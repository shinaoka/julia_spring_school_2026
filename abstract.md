# Julia Spring School 2026 概要（abstract）

Julia は「使いやすさと速さの両立」を志向して設計されたプログラミング言語である。2025年には Google Colab による Julia の公式サポートが開始されたほか、APS DCOMP や SIAM が JuliaCon 2025 に参画するなど、今後の発展が期待されている。
本講義では、強力なコーディング能力をもつ生成AIを「相棒」として、科学計算をJuliaで行うための基礎を学ぶ。

前半3コマは品岡（大野担当分を代講）・水野が担当し、Julia の環境構築から出発して、GitHub を起点とする開発フロー（clone→編集→commit→push）を体験する。短い題材コードを用いて、型・多重ディスパッチ・broadcast といった Julia の抽象化を読み解きつつ、生成AIの提案をテストと計測で検証しながら改良していく流れを実践する。

後半2コマは金賀が担当し、量子マスター方程式の数値解析への応用例を詳述した後、これを題材としてパフォーマンス解析・最適化の手法を議論する。加えて、Journal of Open Source Software 等への投稿を見据えたテスト設計や、研究室内でのプライベート・レジストリ運用など、研究ソフトウェア開発の実践的手法を紹介する。

---

## 0. 受講前提とゴール

- 前提
  - Git / GitHub の基礎操作（前日講義でカバー済み）
  - GitHub アカウントを持っていること
  - GitHub CLI（gh）を使えること
  - 手元の環境に Julia / VS Code がインストール可能であること
- この講義で目指すゴール
  - LLM（VS Code Copilot Pro など）を相棒にして Julia コードを書かせ・読めるようになる
  - Julia の抽象化（関数・型・broadcast）の「何がおいしいか」を体感する
  - プロジェクト環境と GitHub を用いた、現代的な開発ワークフローの入り口を経験する

---

## 1. 題材A：GitHub から始める「現代的な開発の入口」

**狙い：最初に “自分のリポジトリ” を持ち、clone→編集→commit→push の流れを 1 回転させる。**

### 1.1 まず GitHub 上でリポジトリ作成
- GitHub で新規リポジトリを作る
  - `Julia` 向けの `.gitignore` を選ぶ
  - `README.md` を作る（最小の説明でよい）

### 1.2 ローカルに clone して VS Code で開く
- `git clone ...`
- VS Code でフォルダを開く
- VS Code で Copilot Chat が使える状態にする（LLM を “相棒” として固定）

### 1.3 LLM に “プロジェクト環境” を作らせる
- ここで `Project.toml` / `Manifest.toml` を導入し、違いを説明する
- VS Code（Julia 拡張）の UI で「環境を有効化（activate）」する

### 1.4 最後に commit & push
- 1コマ目の最後に `commit` → `push`
- ここで問いを投げる：
  - **「`Manifest.toml` って結局なんだろう？」**
  - “なぜ存在するか / いつ必要か / いつ邪魔か” を次の題材へ接続

---

## 2. 題材B：Julia の抽象化（関数・型・broadcast）を “読める/使える” にする

**狙い：LLM が生成する Julia を “読める” ようにし、最小限の抽象化を自分で判断できるようにする。**

### 2.1 前回コードの再訪：関数化（抽象化）の第一歩
- 第 1 コマの π 推定コードをベースに
  - LLM に「`estimate_pi(N)` の形に関数として整理して」と依頼
- 抽象化とは何か
  - パターンを一箇所にまとめる
  - 引数で違いを表現する
  - 実験条件を変更しやすくする

### 2.2 Julia 基本文法の最小セット
- LLM が生成するコードを読めるようにするための最低限
  - 数値・文字列・配列（ベクトル・行列）
  - for ループ・if 文・簡単な内包表記
  - REPL モード（通常 / パッケージ / シェル）の位置づけ
- 詳細な文法講義ではなく、「読めるようになること」を主眼に

### 2.3 関数と多重ディスパッチの入り口
- 関数 = メソッドの集合という視点
- 型ごとに振る舞いを変えられることのイメージ
  - 例：スカラー / ベクトル / 行列に対する同名関数
- LLM に依頼
  - 「この関数を、別の型（例：整数・浮動小数）用に拡張して」といったプロンプト例

### 2.4 broadcast の意味を丁寧に理解する
- for ループ版の π 推定と、`.` を使った broadcast 版の対応関係
  - 例：`for` で書いた処理を LLM に「broadcast で書き換えて」と依頼
- broadcast のメリット
  - コードの短さ・可読性
  - 高速化のポテンシャル（詳細は第 3 コマ）

### 2.5 小さな一般化：抽象化の効果を感じる
- 例：
  - π 推定を「2 次元 → 高次元」へ拡張
  - 別の簡単な積分問題や乱数分布に応用
- ねらい
  - 一度抽象化しておくと、問題設定を変えたときに LLM との対話が楽になることを体感

### 2.6 ふり返り
- 今日整理したこと
  - 関数化・型・多重ディスパッチの入り口
  - broadcast の意味と for ループとの対応
- 次回のテーマ
  - JIT コンパイルとベンチマークツールを用いた「性能評価」の基礎

---

## 3. 題材C：性能評価（JIT と BenchmarkTools）と、改善サイクル

**狙い：計測の落とし穴を避け、LLM と一緒に「改善→再計測→共有」のサイクルを回す。**

### 3.1 JIT コンパイルのざっくりした説明
- ポイント
  - 最初の 1 回目の呼び出しでコンパイルが走る（遅い）
  - 実際に渡された引数の「型」に応じて最適化される
- LLM に依頼
  - 「Julia の JIT を高校生に説明するつもりで図解して」といった説明プロンプト

### 3.2 「ダメな計測」と BenchmarkTools の必要性
- 例：`@time estimate_pi(10^7)` を何度か実行するだけのコード
  - 問題点：コンパイル時間が混ざる、結果が安定しない
- LLM に依頼
  - 「この計測方法の問題点を指摘して、より良い方法を教えて」と質問
- BenchmarkTools.jl の基本
  - `using BenchmarkTools`
  - `@btime` マクロ
  - `$` 補間の意味（グローバル変数の影響と回避）

### 3.3 プロジェクト環境と GitHub ワークフロー（復習）
- 題材Aで作ったリポジトリを使い、作業の再現性（`instantiate`）を意識して回す

### 3.4 「遅いコード」を LLM と一緒に高速化する
- 題材案
  - 平均・分散計算などの統計処理
  - 2 重 for ループによる距離行列計算など
- 流れ
  1. プロジェクトのテスト or ベンチマークを実行し、「遅い」ことを確認
  2. コードと観測結果を LLM に提示し、「高速化案を出して」と依頼
  3. 提案された修正版を適用し、`@btime` で改善を確認
- ねらい
  - LLM を「性能改善の相談相手」として使う体験
  - プロジェクト環境（`Project.toml` / `Pkg.activate`）の雰囲気に慣れる

### 3.5 GitHub への反映
- 時間に応じて
  - 修正をコミットし、自分の Fork に push
  - （余裕があれば）Pull Request 作成まではデモまたは課題として提示

### 3.6 まとめ
- 3 コマを通してできるようになったこと
  - LLM に Julia コードを書かせる・読ませる・説明させる
  - 抽象化（関数・型・broadcast）の基本的な発想
  - JIT と BenchmarkTools による性能評価の入り口
  - プロジェクト環境と GitHub を使った、簡単な開発サイクル
- 今後への接続
  - より本格的な物理モデル（例：イジング模型など）やパッケージ開発への発展
